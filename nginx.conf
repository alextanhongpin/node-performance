worker_processes auto;

# Number of file descriptors used for Nginx. This is set in the OS with 'ulimit -n 200000'
# or using /etc/security/limits.conf
# Edit /etc/security/limits.conf in order to increase hard and soft opened files allowed
#	* hard nproc 200000
#	* soft nproc 200000
worker_rlimit_nofile 7168;

events { 
  worker_connections 7168; 

  # Essential for linux, optimized to server many clients with each thread
  use epoll;

  # Accept as many connections as possible, after nginx gets notification about a new
  # connection. May flood worker_connections, if that optios is set too low
  multi_accept on;
}


http {
  # This should be as close to your average response time as possible. 
  # Set it higher and you are wasting server resources, potentially: significantly affecting performance. 
  # Set it lower and you are not utilizing keep-alives on most of your requests, slowing down client. We assume that on a fast system, most requests return in under ~ 5seconds.
  # Timeout for keep-alive connections. Server will close connections after this time.
  keepalive_timeout 10; # 10

  # Number of requests a client can make over the keep-alive connection. This is set high for testing. (default is: 100)
  keepalive_requests 10240; 

  # send the client a "request timed out" if the body is not loaded by this time. Default 60. (default is: 60 seconds)
  # client_header_timeout 30;  
  
  # (default is: 60 seconds)
  # client_body_timeout 10; 

  # Sets a timeout for transmitting a response to the client. The timeout is set only between two successive write operations, not for the transmission of the whole response. If the client does not receive anything within this time, the connection is closed.
  # (default is: 60 seconds)
  # send_timeout 10; 


  # Sendfile copies data between one FD and other from within the kernel. 
  # More efficient than read() + write(), since the requires transferring data to and from the user space.
  sendfile on; 
  
  # Tcp_nopush causes nginx to attempt to send its HTTP response head in one packet, 
  # instead of using partial frames. This is useful for prepending headers before calling sendfile, 
  # or for throughput optimization.
  tcp_nopush on;
  
  # don't buffer data-sends (disable Nagle algorithm). Good for sending frequent small bursts of data in real time.
  tcp_nodelay on;  
  
  # allow the server to close the connection after a client stops responding. Frees up socket-associated memory.
  reset_timedout_connection on; 
  
  # If the client stops reading data, free up the stale client connection after this much time. Default 60.
  send_timeout 2;

  upstream node-app {
      least_conn;
      server docker.for.mac.localhost:3000 weight=10 max_fails=3 fail_timeout=30s;
  }
    
  server {
    # Buffer log writes to speed up IO, or disable them altogether
    #access_log /var/log/nginx/access.log main buffer=16k;
    access_log off;

    # Open files
    # How to know how much open files u consume?
    #	ulimit -n   # open files limit per process
    #	lsof | grep nginx | wc -l  # count how many open files an app is taking
    #	cat /proc/sys/fs/file-max    # get max open files allowed

    # Caches information about open FDs, freqently accessed files.
    # Changing this setting, in my environment, brought performance up from 560k req/sec, to 904k req/sec.
    # I recommend using some varient of these options, though not the specific values listed below.
    # open_file_cache max=200000 inactive=5s; 
    # open_file_cache_valid 15s; 
    # open_file_cache_min_uses 1;
    # open_file_cache_errors off;

    listen 80;

    location / {
      proxy_pass http://node-app;
      proxy_http_version 1.1;
      proxy_set_header Upgrade $http_upgrade;
      proxy_set_header Connection 'upgrade';
      proxy_set_header Host $host;
      proxy_cache_bypass $http_upgrade;
    }
  }
}

#  /etc/sysctl.conf
# net.core.somaxconn = 65536
# net.core.netdev_max_backlog â€“ The rate at which packets are buffered by the network card before being handed off to the CPU. Increasing the value can improve performance on machines with a high amount of bandwidth. Check the kernel log for errors related to this setting, and consult the network card documentation for advice on changing it.
# net.ipv4.tcp_max_tw_buckets = 1440000
# fs.file-max = 20480
# net.ipv4.tcp_fin_timeout 15 # default: 60 sec. Shorter values allow free-ing up temporart porst (used for backend connections) faster. Important for high loads.a